{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da82cc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from datetime import datetime\n",
    "import re\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "from emoji import core\n",
    "from langdetect import detect\n",
    "import fasttext\n",
    "import openpyxl\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "from apiclient.errors import HttpError\n",
    "# from config.keys import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# jupyter notebook cell 너비 조절\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f287d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAvFifiyynRtJ-HV2cZY0ukO4Wxsjs2noQ'\n",
    "# video_id = 'SlGkck6xWWI'          # BABYMONSTER - ASA (LIVE PERFORMANCE)\n",
    "# video_id = 'y54f8yCK1Lc'          # BABYMONSTER - RORA (LIVE PERFORMANCE)\n",
    "# video_id = '79PhScM2_3k'          # BABYMONSTER - PHARITA (LIVE PERFORMANCE)\n",
    "# video_id = 'rCN3xgEPEwo'          # BABYMONSTER - RUKA (LIVE PERFORMANCE)\n",
    "video_id = 'asYFbkO450I'          # BABYMONSTER - Introducing RUKA\n",
    "\n",
    "comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720de425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(response, videoId):\n",
    "    while response:\n",
    "        for item in response['items']:\n",
    "            comment_row = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append(\n",
    "                [comment_row['textDisplay'], comment_row['authorDisplayName'], comment_row['publishedAt'], comment_row['likeCount']])\n",
    "            \n",
    "            if item['snippet']['totalReplyCount'] > 0:\n",
    "                for reply_item in item['replies']['comments']:\n",
    "                    reply = reply_item['snippet']\n",
    "                    comments.append(\n",
    "                        [reply['textDisplay'], reply['authorDisplayName'], reply['publishedAt'], reply['likeCount']])\n",
    "                    \n",
    "        # nextToken 없을 때까지 반봅\n",
    "        if 'nextPageToken' in response:\n",
    "            response = api_obj.commentThreads().list(part='snippet,replies', videoId=videoId, pageToken=response['nextPageToken'], maxResults=100).execute()\n",
    "            \n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1cbf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "api_obj = build('youtube', 'v3', developerKey=api_key)\n",
    "target = api_obj.commentThreads().list(\n",
    "    part='snippet, replies', videoId=video_id, maxResults=100, textFormat='plainText').execute()\n",
    "    \n",
    "# global variable인 coemments list에서 댓글 관리\n",
    "get_comments(target, video_id)\n",
    "df = pd.DataFrame(comments)\n",
    "    \n",
    "nowdate = '/' + date.today().strftime('%Y%m%d')\n",
    "nowtime = datetime.now().strftime('%H%M%S')\n",
    "RAWPATH = '/data/yg_projects/listening_mind/03_BABYMONSTER/'\n",
    "dirpath = RAWPATH + video_id + nowdate\n",
    "if os.path.isdir(dirpath) is False:\n",
    "    os.makedirs(dirpath)\n",
    "        \n",
    "\"\"\"\n",
    "/raw/{videoId}/20230131/plaintext_111400.xlsx   -> 실제 API를 찌르고 나온 response에서 댓글을 그대로 저장\n",
    "/raw/{videoId}/20230131/results_111400.xlsx     -> emoji 등을 제거하고 남은 댓글들로 fasttext 모듈을 통해 언어 분석을 진행한 상태\n",
    "/raw/{videoId}/20230131/lang_raw_111400.xlsx    -> 각 언어의 빈도수, 이걸로 댓글언어비율 파일을 따로 작성함\n",
    "\"\"\"\n",
    "    \n",
    "df.to_excel(dirpath + f'/plaintext_{nowtime}.xlsx', header=['comment', 'author', 'date', 'num_likes'], index=None)\n",
    "    \n",
    "# language detection w. FastText\n",
    "langs = {}\n",
    "save_results = []\n",
    "model = fasttext.load_model(\"/data/yg_projects/listening_mind/03_BABYMONSTER/ygu-youtube-video-lang/lid.176.bin\")\n",
    "total_len = 0\n",
    "for i in range(0, df.shape[0]):\n",
    "    comment = df.loc[i, 0]\n",
    "    cleantext = BeautifulSoup(str(comment), 'lxml').text.replace(\"\\n\", \"\")\n",
    "    remove_emoji = core.replace_emoji(str(cleantext), replace=\"\")\n",
    "        \n",
    "    if remove_emoji == \"\":\n",
    "        continue\n",
    "            \n",
    "    total_len += 1\n",
    "    first_predict = model.predict(remove_emoji, k=3)[0][0].replace(\"__label__\", \"\")\n",
    "        \n",
    "    if first_predict not in langs:\n",
    "        langs[first_predict] = 1\n",
    "            \n",
    "    else:\n",
    "        langs[first_predict] += 1\n",
    "            \n",
    "    userId = df.loc[i, 1]\n",
    "    pub_date = df.loc[i, 2][:]\n",
    "    num_likes = df.loc[i, 3]\n",
    "    save_results.append([remove_emoji, first_predict, userId, pub_date, num_likes])\n",
    "        \n",
    "df = pd.DataFrame(save_results)\n",
    "df.to_excel(dirpath + f'/results_{nowtime}.xlsx', header=['comment', 'lang', 'author', 'date', 'num_likes'], index=None)\n",
    "    \n",
    "sorted_dict = sorted(langs.items(), key=lambda item: item[1], reverse=True, )\n",
    "lang_results = []\n",
    "for row in sorted_dict:\n",
    "    lang_results.append([row[0], row[1]])\n",
    "    \n",
    "df = pd.DataFrame(lang_results)\n",
    "df.to_excel(dirpath + f'/lang_raw_{nowtime}.xlsx', header=['lang', 'num'], index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d47952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
